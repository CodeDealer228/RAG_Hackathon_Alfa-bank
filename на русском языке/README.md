# Альфа-Банк RAG-система

Система поиска по базе знаний финансовых продуктов. Система извлекает топ-5 наиболее релевантных страниц для вопросов пользователей о продуктах Альфа-Банка.

**Тестовый скор: Hit@5 = 0.65**

## Быстрый старт

### Установка зависимостей
```bash
pip install sentence-transformers faiss-cpu rank-bm25 transformers torch
```

### Запуск блокнотов
```bash
# Базовый подход v1.0 (Hit@5 = 0.10)
jupyter notebook 01_bazovyy_gte_chunking.ipynb

# Базовый подход v2.0 (Hit@5 = 0.30)
jupyter notebook 02_bazovyy_uluchshennyy_chunking.ipynb

# Финальный подход (Hit@5 = 0.65)
jupyter notebook 03_finalnyy_gibridnyy_poisk.ipynb
```

## Эволюция подходов

| Версия | Метод | Скор | Ключевой вывод |
|--------|-------|------|----------------|
| v1.0 | GTE + чанкинг по предложениям | 0.10 | Начальный базовый уровень |
| v2.0 | GTE + чанкинг по словам (350 слов) | 0.30 | Лучший чанкинг = 3x улучшение |
| **Финал** | **BM25 + расширение запросов + плотные + CrossEncoder** | **0.65** | Гибридный подход = 6.5x улучшение |

## Финальная методология

1. **Расширение запросов** - Добавление доменных синонимов (вклад → депозит, накопление...)
2. **Поиск BM25** - Быстрое лексическое сопоставление (30% вес)
3. **Плотные эмбеддинги** - Семантическое сопоставление с MPNet (70% вес)
4. **Гибридное слияние** - Объединение обоих сигналов
5. **Переранжирование CrossEncoder** - Попарная семантическая оценка для топ-5

## Датасет

- **Входные данные**: ~1 000 финансовых вопросов на русском + ~20 000 веб-страниц
- **Выходные данные**: Топ-5 ID страниц на запрос в формате `[id1, id2, id3, id4, id5]`
- **Метрика**: Hit@5 (охват правильного ответа в топ-5)

## Результаты

- **Базовый v1.0**: 0.10 (слабая модель + плохой чанкинг)
- **Базовый v2.0**: 0.30 (улучшенная стратегия чанкинга)
- **Финальный**: 0.65 (гибридный поиск + продвинутое переранжирование)

## Технологический стек

- **Эмбеддинги**: SentenceTransformer (MPNet)
- **Поиск**: FAISS (плотный) + BM25 (лексический)
- **Переранжирование**: CrossEncoder (ms-marco-MiniLM)
- **Фреймворк**: PyTorch, HuggingFace Transformers

## Файлы

- `01_bazovyy_gte_chunking.ipynb` - GTE с разбиением по предложениям
- `02_bazovyy_uluchshennyy_chunking.ipynb` - Улучшенный чанкинг на уровне слов
- `03_finalnyy_gibridnyy_poisk.ipynb` - BM25 + плотный + CrossEncoder
- `PROEKT.md` - Подробный отчёт
- `submission_*.csv` - Предсказания для каждого подхода

## Ссылки

- [SentenceTransformer](https://www.sbert.net/)
- [FAISS](https://github.com/facebookresearch/faiss)
- [rank-bm25](https://github.com/dorianbrown/rank_bm25)

## Хакатон

Конкурс RAG-системы Альфа-Банка | Ноябрь 2025
